# StyleGen
StyleGen is a machine learning training pipeline leveraging stable diffusion processes such as Dreambooth-LORA and Textual Inversion in order to allow users to create models that generate audio that mimics the style of a song but with minor changes through text commands, all done from Google Colab free-tier notebooks through optimization.

#V2 Demos (Using Dreambooth-LoRA) (Yielded best results as of now) 
The first demo will be the results of using StyleGen on 5 5-second snippets, converted to spectrograms, of "Loopster" by Kevin MacLeod to create new pieces of audio with a customized generative model fine-tuned to produce audio in the same style. 

The audio is converted to mp4 to make it playable from GitHub.

Original Song: 

https://github.com/MouseTrap42/StyleGen/assets/125787399/28a26d53-e902-449d-9179-a4db5320dabf

Dataset of 5 5-second snippets (512x512 spectrograms): 
https://drive.google.com/drive/folders/1cs7NJLqAzMjZhtDLfKmOA1lmQfhOrfqB?usp=share_link


StyleGen Outputs:

prompt: "<loopster_style>, quiet bass notes, peaceful ambience"


prompt: "<loopster_style>, style electronica music_vibrant, synths and electric drums" 









